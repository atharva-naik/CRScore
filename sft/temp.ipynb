{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-train_all_classified.json\"\n",
    "valid_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-valid.jsonl\"\n",
    "\n",
    "# Step 1: Convert dataset to the required format\n",
    "def convert_to_chat_format(train_path, valid_path):\n",
    "    \"\"\"\n",
    "    Converts the dataset into a list of dicts with 'content' and 'role' keys.\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    train_df = pd.read_json(train_path, lines=True)\n",
    "    valid_df = pd.read_json(valid_path, lines=True)\n",
    "\n",
    "    # Helper function to process each dataset\n",
    "    def process_dataset(df):\n",
    "        formatted_data = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            # First dict: user input\n",
    "            user_dict = {\"content\": row[\"patch\"], \"role\": \"user\"}\n",
    "            # Second dict: assistant output\n",
    "            assistant_dict = {\"content\": row[\"msg\"], \"role\": \"assistant\"}\n",
    "            # Add both to the list as a conversation pair\n",
    "            formatted_data.append([user_dict, assistant_dict])\n",
    "        return formatted_data\n",
    "\n",
    "    # Process train and validation datasets\n",
    "    train_data = process_dataset(train_df)\n",
    "    valid_data = process_dataset(valid_df)\n",
    "\n",
    "    return train_data, valid_data\n",
    "\n",
    "# Step 2: Push to Hugging Face Hub\n",
    "def push_to_hub(train_data, valid_data, repo_name, token):\n",
    "    \"\"\"\n",
    "    Pushes the processed dataset to Hugging Face Hub.\n",
    "    \"\"\"\n",
    "    # Convert lists of dicts to Hugging Face Dataset format\n",
    "    train_dataset = Dataset.from_dict({\"conversations\": train_data})\n",
    "    valid_dataset = Dataset.from_dict({\"conversations\": valid_data})\n",
    "\n",
    "    # Combine into a DatasetDict\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": valid_dataset,\n",
    "    })\n",
    "\n",
    "    # Save locally before pushing (optional)\n",
    "    dataset_dict.save_to_disk(\"./processed_dataset\")\n",
    "\n",
    "    # Push to Hugging Face Hub\n",
    "    dataset_dict.push_to_hub(repo_name, token=token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109274/109274 [00:05<00:00, 18914.85it/s]\n",
      "100%|██████████| 10319/10319 [00:00<00:00, 21406.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# File paths for your datasets\n",
    "train_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-train_all_classified.json\"\n",
    "valid_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-valid.jsonl\"\n",
    "\n",
    "# Convert datasets to chat format\n",
    "train_data, valid_data = convert_to_chat_format(train_path, valid_path)\n",
    "\n",
    "# Hugging Face Hub details\n",
    "repo_name = \"conferencesubmissionmodel/crscore_SFT\"  # Replace with your repo name on HF Hub\n",
    "hf_token = \"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\"  # Replace with your personal access token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c7feca663f4d9abc56fc2a3da02f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/109274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57a4e1d9ebc4319a94ad38b9949b97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e5161ac78b4078aea61495a550bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d819b178e524857862d823ce28061a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/110 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2e93bf24114cf99f2c233e6e10f35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343d52f8f65a4506b44a28b3bdb79059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Push dataset to the Hub\n",
    "push_to_hub(train_data, valid_data, repo_name, hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442a6a6d718d4ebbb100554491010e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fd4be9a26447449ac10aec6ac4560e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c273dc040a7a497dad2295540b714cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d574d0bc6b10494c8dc1778565dfe230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-train_all_classified.json\"\n",
    "train_df = pd.read_json(train_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize first 1000 samples and then give me avg token length\n",
    "\n",
    "token_lens = []\n",
    "for i in range(1000):\n",
    "    token_lens.append(len(tokenizer(train_df[\"oldf\"][i]+train_df[\"patch\"][i])[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel\n",
    "# from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valid_path = \"/home/mkapadni/work/crscore_plus_plus/Comment_Generation/msg-valid.jsonl\"\n",
    "\n",
    "valid_df = pd.read_json(valid_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patch</th>\n",
       "      <th>y</th>\n",
       "      <th>oldf</th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>msg</th>\n",
       "      <th>proj</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@@ -231,4 +231,8 @@ def setup_app(app):\\n     ...</td>\n",
       "      <td>1</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#\\n# This file is par...</td>\n",
       "      <td>1</td>\n",
       "      <td>16014</td>\n",
       "      <td>Should we call it `is_list`?</td>\n",
       "      <td>inveniosoftware-invenio</td>\n",
       "      <td>py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@@ -44,7 +44,7 @@ namespace OpenTelemetry.Trac...</td>\n",
       "      <td>1</td>\n",
       "      <td>// &lt;copyright file=\"TracerProviderBuilderExten...</td>\n",
       "      <td>1</td>\n",
       "      <td>18299</td>\n",
       "      <td>in the instrumentation example, should we use ...</td>\n",
       "      <td>open-telemetry-opentelemetry-dotnet</td>\n",
       "      <td>.cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@@ -25,7 +25,7 @@ from scapy.modules.six.moves...</td>\n",
       "      <td>1</td>\n",
       "      <td>## This file is part of Scapy\\n## See http://w...</td>\n",
       "      <td>1</td>\n",
       "      <td>12313</td>\n",
       "      <td>Why this change ? Is it useful ?</td>\n",
       "      <td>secdev-scapy</td>\n",
       "      <td>py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@ -0,0 +1,4 @@\\n+const titleNode = virtualNod...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>15216</td>\n",
       "      <td>I know this is a nitpick, but don't we always ...</td>\n",
       "      <td>dequelabs-axe-core</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@@ -37,6 +37,11 @@ public class EMailValidator...</td>\n",
       "      <td>1</td>\n",
       "      <td>package edu.harvard.iq.dataverse;\\n\\nimport st...</td>\n",
       "      <td>1</td>\n",
       "      <td>37751</td>\n",
       "      <td>We should reformat this emails in the test to ...</td>\n",
       "      <td>IQSS-dataverse</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               patch  y  \\\n",
       "0  @@ -231,4 +231,8 @@ def setup_app(app):\\n     ...  1   \n",
       "1  @@ -44,7 +44,7 @@ namespace OpenTelemetry.Trac...  1   \n",
       "2  @@ -25,7 +25,7 @@ from scapy.modules.six.moves...  1   \n",
       "3  @@ -0,0 +1,4 @@\\n+const titleNode = virtualNod...  1   \n",
       "4  @@ -37,6 +37,11 @@ public class EMailValidator...  1   \n",
       "\n",
       "                                                oldf  idx     id  \\\n",
       "0  # -*- coding: utf-8 -*-\\n#\\n# This file is par...    1  16014   \n",
       "1  // <copyright file=\"TracerProviderBuilderExten...    1  18299   \n",
       "2  ## This file is part of Scapy\\n## See http://w...    1  12313   \n",
       "3                                                       1  15216   \n",
       "4  package edu.harvard.iq.dataverse;\\n\\nimport st...    1  37751   \n",
       "\n",
       "                                                 msg  \\\n",
       "0                       Should we call it `is_list`?   \n",
       "1  in the instrumentation example, should we use ...   \n",
       "2                   Why this change ? Is it useful ?   \n",
       "3  I know this is a nitpick, but don't we always ...   \n",
       "4  We should reformat this emails in the test to ...   \n",
       "\n",
       "                                  proj  lang  \n",
       "0              inveniosoftware-invenio    py  \n",
       "1  open-telemetry-opentelemetry-dotnet   .cs  \n",
       "2                         secdev-scapy    py  \n",
       "3                   dequelabs-axe-core    js  \n",
       "4                       IQSS-dataverse  java  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -231,4 +231,8 @@ def setup_app(app):\n",
      "         )\n",
      "         return rv\n",
      " \n",
      "+    @app.template_test('list')\n",
      "+    def _is_list(value):\n",
      "+        return isinstance(value, list)\n",
      "+\n",
      "     return app\n"
     ]
    }
   ],
   "source": [
    "print(valid_df['patch'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\n",
      "#\n",
      "# This file is part of Invenio.\n",
      "# Copyright (C) 2012, 2013, 2014, 2015 CERN.\n",
      "#\n",
      "# Invenio is free software; you can redistribute it and/or\n",
      "# modify it under the terms of the GNU General Public License as\n",
      "# published by the Free Software Foundation; either version 2 of the\n",
      "# License, or (at your option) any later version.\n",
      "#\n",
      "# Invenio is distributed in the hope that it will be useful, but\n",
      "# WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
      "# General Public License for more details.\n",
      "#\n",
      "# You should have received a copy of the GNU General Public License\n",
      "# along with Invenio; if not, write to the Free Software Foundation, Inc.,\n",
      "# 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n",
      "\n",
      "\"\"\"Additional extensions and filters for jinja2 module.\"\"\"\n",
      "\n",
      "import re\n",
      "\n",
      "from flask import _request_ctx_stack, g, request, url_for\n",
      "\n",
      "from flask_login import current_user\n",
      "\n",
      "from jinja2 import ChoiceLoader\n",
      "\n",
      "from six import iteritems, string_types\n",
      "\n",
      "from werkzeug.routing import BuildError\n",
      "\n",
      "from .bccache import BytecodeCacheWithConfig\n",
      "from .context_processor import setup_app as context_processor_setup_app\n",
      "from .loader import OrderAwareDispatchingJinjaLoader\n",
      "\n",
      "ENV_PREFIX = '_collected_'\n",
      "\n",
      "\n",
      "def render_template_to_string(input, _from_string=False, **context):\n",
      "    \"\"\"Render a template from the template folder with the given context.\n",
      "\n",
      "    Code based on\n",
      "    `<https://github.com/mitsuhiko/flask/blob/master/flask/templating.py>`_\n",
      "\n",
      "    :param input: the string template, or name of the template to be\n",
      "                  rendered, or an iterable with template names\n",
      "                  the first one existing will be rendered\n",
      "    :param context: the variables that should be available in the\n",
      "                    context of the template.\n",
      "    :return: a string\n",
      "\n",
      "    \"\"\"\n",
      "    ctx = _request_ctx_stack.top\n",
      "    ctx.app.update_template_context(context)\n",
      "    if _from_string:\n",
      "        template = ctx.app.jinja_env.from_string(input)\n",
      "    else:\n",
      "        template = ctx.app.jinja_env.get_or_select_template(input)\n",
      "    return template.render(context)\n",
      "\n",
      "\n",
      "def inject_utils():\n",
      "    \"\"\"Inject variables and functions to jinja execution context.\n",
      "\n",
      "    In particular it will add:\n",
      "\n",
      "    - ``url_for``: an Invenio specific wrapper of Flask url_for, that will let\n",
      "      you obtain URLs for non Flask-native handlers (i.e. not yet ported\n",
      "      Invenio URLs)\n",
      "    - ``_``: this can be used to automatically translate a given string.\n",
      "    - ``is_language_rtl``: True if the chosen language should be read right to\n",
      "      left.\n",
      "    \"\"\"\n",
      "    from invenio.base.i18n import is_language_rtl\n",
      "    from invenio.modules.records.api import get_record\n",
      "    from invenio.utils.url import create_url, get_canonical_and_alternates_urls\n",
      "\n",
      "    def invenio_url_for(endpoint, **values):\n",
      "        try:\n",
      "            return url_for(endpoint, **values)\n",
      "        except BuildError:\n",
      "            if re.match(\"https?://\", endpoint, re.IGNORECASE):\n",
      "                return endpoint\n",
      "            if endpoint.startswith('.'):\n",
      "                endpoint = request.blueprint + endpoint\n",
      "            url = create_url('/' + endpoint.replace('.', '/'), values, False)\n",
      "            return url.decode('utf-8')\n",
      "\n",
      "    user = current_user._get_current_object()\n",
      "    canonical_url, alternate_urls = get_canonical_and_alternates_urls(\n",
      "        request.path)\n",
      "    alternate_urls = dict((ln.replace('_', '-'), alternate_url)\n",
      "                          for ln, alternate_url in iteritems(alternate_urls))\n",
      "    return dict(\n",
      "        current_user=user,\n",
      "        is_language_rtl=is_language_rtl,\n",
      "        canonical_url=canonical_url,\n",
      "        alternate_urls=alternate_urls,\n",
      "        get_record=get_record,\n",
      "        url_for=invenio_url_for,\n",
      "    )\n",
      "\n",
      "\n",
      "def setup_app(app):\n",
      "    \"\"\"\n",
      "    Extend application template filters with custom filters and fixes.\n",
      "\n",
      "    List of applied filters:\n",
      "\n",
      "    - filesizeformat\n",
      "    - path_join\n",
      "    - quoted_txt2html\n",
      "    - invenio_format_date\n",
      "    - invenio_pretty_date\n",
      "    - invenio_url_args\n",
      "    \"\"\"\n",
      "    import os\n",
      "    from datetime import datetime\n",
      "    from invenio.utils.date import convert_datetext_to_dategui, \\\n",
      "        convert_datestruct_to_dategui, pretty_date\n",
      "\n",
      "    from . import config\n",
      "    app.config.from_object(config)\n",
      "\n",
      "    context_processor_setup_app(app)\n",
      "    app.context_processor(inject_utils)\n",
      "\n",
      "    if app.config.get('JINJA2_BCCACHE', False):\n",
      "        app.jinja_options = dict(\n",
      "            app.jinja_options,\n",
      "            auto_reload=app.config.get('JINJA2_BCCACHE_AUTO_RELOAD', False),\n",
      "            cache_size=app.config.get('JINJA2_BCCACHE_SIZE', -1),\n",
      "            bytecode_cache=BytecodeCacheWithConfig(app))\n",
      "\n",
      "    # Let's customize the template loader to look into packages\n",
      "    # and application templates folders.\n",
      "    jinja_loader = ChoiceLoader([\n",
      "        OrderAwareDispatchingJinjaLoader(app),\n",
      "        app.jinja_loader,\n",
      "    ])\n",
      "    app.jinja_loader = jinja_loader\n",
      "\n",
      "    for ext in app.config.get('JINJA2_EXTENSIONS', []):\n",
      "        try:\n",
      "            app.jinja_env.add_extension(ext)\n",
      "        except Exception:\n",
      "            app.logger.exception(\n",
      "                'Problem with loading extension: \"{0}\"'.format(ext))\n",
      "\n",
      "    def test_not_empty(v):\n",
      "        return v is not None and v != ''\n",
      "\n",
      "    @app.template_filter('u')\n",
      "    def tounicode(value):\n",
      "        if isinstance(value, str):\n",
      "            return value.decode('utf8')\n",
      "        return value\n",
      "\n",
      "    @app.template_filter('s')\n",
      "    def tostr(value):\n",
      "        if not isinstance(value, str):\n",
      "            if isinstance(value, unicode):\n",
      "                value = value.encode('utf8')\n",
      "            value = str(value)\n",
      "        return value\n",
      "\n",
      "    @app.template_filter('prefix')\n",
      "    def _prefix(value, prefix=''):\n",
      "        return prefix + value if test_not_empty(value) else ''\n",
      "\n",
      "    @app.template_filter('suffix')\n",
      "    def _suffix(value, suffix=''):\n",
      "        return value + suffix if test_not_empty(value) else ''\n",
      "\n",
      "    @app.template_filter('wrap')\n",
      "    def _wrap(value, prefix='', suffix=''):\n",
      "        return prefix + value + suffix if test_not_empty(value) else ''\n",
      "\n",
      "    @app.template_filter('sentences')\n",
      "    def _sentences(value, limit, separator='. '):\n",
      "        \"\"\"Return first `limit` number of sentences ending by `separator`.\"\"\"\n",
      "        return separator.join(value.split(separator)[:limit])\n",
      "\n",
      "    @app.template_filter('path_join')\n",
      "    def _os_path_join(d):\n",
      "        \"\"\"Shortcut for `os.path.join`.\"\"\"\n",
      "        return os.path.join(*d)\n",
      "\n",
      "    @app.template_filter('quoted_txt2html')\n",
      "    def _quoted_txt2html(*args, **kwargs):\n",
      "        from invenio.utils.mail import email_quoted_txt2html\n",
      "        return email_quoted_txt2html(*args, **kwargs)\n",
      "\n",
      "    @app.template_filter('invenio_format_date')\n",
      "    def _format_date(date):\n",
      "        \"\"\"\n",
      "        Format a date into a human friendly format.\n",
      "\n",
      "        It uses :py:func:`invenio.utils.date.convert_datetext_to_dategui`\n",
      "        \"\"\"\n",
      "        if isinstance(date, datetime):\n",
      "            return convert_datestruct_to_dategui(\n",
      "                date.timetuple(),\n",
      "                getattr(g, 'ln', app.config['CFG_SITE_LANG'])).decode('utf-8')\n",
      "        return convert_datetext_to_dategui(\n",
      "            date, getattr(g, 'ln', app.config['CFG_SITE_LANG'])\n",
      "        ).decode('utf-8')\n",
      "\n",
      "    @app.template_filter('invenio_pretty_date')\n",
      "    def _pretty_date(date):\n",
      "        \"\"\"\n",
      "        Format a timestamp into a human friendly format.\n",
      "\n",
      "        It uses :py:func:`invenio.utils.date.pretty_date`\n",
      "        \"\"\"\n",
      "        if isinstance(date, datetime) or isinstance(date, string_types):\n",
      "            return pretty_date(\n",
      "                date, ln=getattr(g, 'ln', app.config['CFG_SITE_LANG']))\n",
      "        return date\n",
      "\n",
      "    @app.template_filter('invenio_url_args')\n",
      "    def _url_args(d, append=u'?', filter=[]):\n",
      "        from jinja2.utils import escape\n",
      "        rv = append + u'&'.join(\n",
      "            u'%s=%s' % (escape(key), escape(value))\n",
      "            for key, value in d.iteritems(True)\n",
      "            if value is not None and key not in filter\n",
      "            # and not isinstance(value, Undefined)\n",
      "        )\n",
      "        return rv\n",
      "\n",
      "    return app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(valid_df['oldf'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_context(oldf, patch, n=3):\n",
    "    \"\"\"\n",
    "    Display code patch with n lines of context before and after.\n",
    "    \n",
    "    Args:\n",
    "        oldf (str): Original file content\n",
    "        patch (str): Patch content in unified diff format\n",
    "        n (int): Number of context lines before and after\n",
    "        \n",
    "    Returns:\n",
    "        str: Integrated code with context\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Split file into lines\n",
    "    oldf_lines = oldf.split('\\n')\n",
    "    \n",
    "    # Extract line number from patch header\n",
    "    match = re.search(r'@@ -(\\d+)', patch)\n",
    "    if not match:\n",
    "        return \"Could not determine patch location\"\n",
    "    \n",
    "    # Get starting line number (1-based) and convert to 0-based index\n",
    "    start_line = int(match.group(1))\n",
    "    idx = start_line - 1\n",
    "    \n",
    "    # Calculate context ranges\n",
    "    before_start = max(0, idx - n)\n",
    "    after_start = idx\n",
    "    after_end = min(len(oldf_lines), after_start + n)\n",
    "    \n",
    "    # Extract added lines from patch (remove '+' prefix)\n",
    "    added_lines = []\n",
    "    found_header = False\n",
    "    for line in patch.split('\\n'):\n",
    "        if line.startswith('@@'):\n",
    "            found_header = True\n",
    "            continue\n",
    "        if found_header:\n",
    "            if line.startswith('+'):\n",
    "                added_lines.append(line[1:])\n",
    "    \n",
    "    # Build result\n",
    "    result = []\n",
    "    \n",
    "    # Lines before patch\n",
    "    for i in range(before_start, idx):\n",
    "        result.append(oldf_lines[i])\n",
    "    \n",
    "    # Patch content (integrated)\n",
    "    result.extend(added_lines)\n",
    "    \n",
    "    # Lines after patch\n",
    "    for i in range(after_start, after_end):\n",
    "        result.append(oldf_lines[i])\n",
    "    \n",
    "    return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rv = append + u'&'.join(\n",
      "            u'%s=%s' % (escape(key), escape(value))\n",
      "            for key, value in d.iteritems(True)\n",
      "            if value is not None and key not in filter\n",
      "            # and not isinstance(value, Undefined)\n",
      "    @app.template_test('list')\n",
      "    def _is_list(value):\n",
      "        return isinstance(value, list)\n",
      "\n",
      "        )\n",
      "        return rv\n",
      "\n",
      "    return app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oldf = valid_df['oldf'][0]\n",
    "patch = valid_df['patch'][0]\n",
    "n = 5 # Number of lines before and after\n",
    "\n",
    "result = get_patch_context(oldf, patch, n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
